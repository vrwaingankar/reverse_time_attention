{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cBishoYRLBK",
        "outputId": "564204f0-13fa-4887-b8f3-db85f7930071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrYbiM5YQ4CL"
      },
      "outputs": [],
      "source": [
        "import pickle as pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.constraints import Constraint\n",
        "from tensorflow.keras.utils import Sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths and other parameters as variables\n",
        "PATH_MODEL = \"/content/drive/MyDrive/MIMIC/output/Model/weights.01.hdf5\"\n",
        "PATH_DATA = \"/content/drive/MyDrive/MIMIC/output/data_test.pkl\"\n",
        "PATH_DICTIONARY = \"/content/drive/MyDrive/MIMIC/output/dictionary.pkl\"\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "HLU7rzeDSnNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def import_model(path):\n",
        "    \"\"\"Import model from given path and assign it to appropriate devices\"\"\"\n",
        "    K.clear_session()\n",
        "    config = tf.compat.v1.ConfigProto(\n",
        "        allow_soft_placement=True, log_device_placement=False\n",
        "    )\n",
        "    config.gpu_options.allow_growth = True\n",
        "    tfsess = tf.compat.v1.Session(config=config)\n",
        "    tf.compat.v1.keras.backend.set_session(tfsess)\n",
        "    model = load_model(\n",
        "        path,\n",
        "        custom_objects={\n",
        "            \"FreezePadding\": FreezePadding,\n",
        "            \"FreezePadding_Non_Negative\": FreezePadding_Non_Negative,\n",
        "        },\n",
        "    )\n",
        "    model_with_attention = Model(\n",
        "        model.inputs,\n",
        "        model.outputs\n",
        "        + [\n",
        "            model.get_layer(name=\"softmax_1\").output,\n",
        "            model.get_layer(name=\"beta_dense_0\").output,\n",
        "        ],\n",
        "    )\n",
        "    return model, model_with_attention"
      ],
      "metadata": {
        "id": "MY2vms0PRWjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_parameters(model):\n",
        "    \"\"\"Extract model arguments that were used during training\"\"\"\n",
        "\n",
        "    class ModelParameters:\n",
        "        \"\"\"Helper class to store model parameters\"\"\"\n",
        "\n",
        "        def __init__(self):\n",
        "            self.num_codes = None\n",
        "            self.numeric_size = None\n",
        "            self.use_time = None\n",
        "            self.emb_weights = None\n",
        "            self.output_weights = None\n",
        "            self.bias = None\n",
        "\n",
        "    params = ModelParameters()\n",
        "    names = [layer.name for layer in model.layers]\n",
        "    params.num_codes = model.get_layer(name=\"embedding\").input_dim - 1\n",
        "    params.emb_weights = model.get_layer(name=\"embedding\").get_weights()[0]\n",
        "    params.output_weights, params.bias = model.get_layer(\n",
        "        name=\"time_distributed_out\"\n",
        "    ).get_weights()\n",
        "    print(\"Model bias: {}\".format(params.bias))\n",
        "    if \"numeric_input\" in names:\n",
        "        params.numeric_size = model.get_layer(name=\"numeric_input\").input_shape[2]\n",
        "        # Add artificial embeddings for each numeric feature and extend the embedding weights\n",
        "        # Numeric embeddings is just 1 for 1 dimension of the embedding which corresponds to taking value as is\n",
        "        numeric_embeddings = np.zeros(\n",
        "            (params.numeric_size, params.emb_weights.shape[1] + params.numeric_size)\n",
        "        )\n",
        "        for i in range(params.numeric_size):\n",
        "            numeric_embeddings[i, params.emb_weights.shape[1] + i] = 1\n",
        "        # Extended embedding is original embedding extended to larger output size and numerics embeddings added\n",
        "        params.emb_weights = np.append(\n",
        "            params.emb_weights,\n",
        "            np.zeros((params.num_codes + 1, params.numeric_size)),\n",
        "            axis=1,\n",
        "        )\n",
        "        params.emb_weights = np.append(params.emb_weights, numeric_embeddings, axis=0)\n",
        "    else:\n",
        "        params.numeric_size = 0\n",
        "    if \"time_input\" in names:\n",
        "        params.use_time = True\n",
        "    else:\n",
        "        params.use_time = False\n",
        "    return params"
      ],
      "metadata": {
        "id": "mFB5oORURcHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FreezePadding_Non_Negative(Constraint):\n",
        "    \"\"\"Freezes the last weight to be near 0 and prevents non-negative embeddings\n",
        "\n",
        "    :param Constraint: Keras sequence constraint\n",
        "    :type Constraint: :class:`tensorflow.keras.constraints.Constraint`\n",
        "    :return: padded tensorflow tensor\n",
        "    :rtype: :class:`tensorflow.Tensor`\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(self, w):\n",
        "        other_weights = K.cast(K.greater_equal(w, 0)[:-1], K.floatx())\n",
        "        last_weight = K.cast(\n",
        "            K.equal(K.reshape(w[-1, :], (1, K.shape(w)[1])), 0.0), K.floatx()\n",
        "        )\n",
        "        appended = K.concatenate([other_weights, last_weight], axis=0)\n",
        "        w *= appended\n",
        "        return w"
      ],
      "metadata": {
        "id": "fi2iEMdfRlBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FreezePadding(Constraint):\n",
        "    \"\"\"Freezes the last weight to be near 0.\n",
        "\n",
        "    :param Constraint: Keras sequence constraint\n",
        "    :type Constraint: :class:`tensorflow.keras.constraints.Constraint`\n",
        "    :return: padded tensorflow tensor\n",
        "    :rtype: :class:`tensorflow.Tensor`\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(self, w):\n",
        "        other_weights = K.cast(K.ones(K.shape(w))[:-1], K.floatx())\n",
        "        last_weight = K.cast(\n",
        "            K.equal(K.reshape(w[-1, :], (1, K.shape(w)[1])), 0.0), K.floatx()\n",
        "        )\n",
        "        appended = K.concatenate([other_weights, last_weight], axis=0)\n",
        "        w *= appended\n",
        "        return w"
      ],
      "metadata": {
        "id": "uypGORUBRrMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceBuilder(Sequence):\n",
        "    \"\"\"Class to properly construct data to sequences\n",
        "\n",
        "    :param Sequence: Customized Sequence class for generating batches of data\n",
        "    :type Sequence: :class:`tensorflow.keras.utils.Sequence`\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, model_parameters):\n",
        "        # Receive all appropriate data\n",
        "        self.codes = data[0]\n",
        "        index = 1\n",
        "        if model_parameters.numeric_size:\n",
        "            self.numeric = data[index]\n",
        "            index += 1\n",
        "\n",
        "        if model_parameters.use_time:\n",
        "            self.time = data[index]\n",
        "\n",
        "        self.num_codes = model_parameters.num_codes\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.numeric_size = model_parameters.numeric_size\n",
        "        self.use_time = model_parameters.use_time\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Compute number of batches.\n",
        "        Add extra batch if the data doesn't exactly divide into batches\n",
        "        \"\"\"\n",
        "        if len(self.codes) % self.batch_size == 0:\n",
        "            return len(self.codes) // self.batch_size\n",
        "        return len(self.codes) // self.batch_size + 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Get batch of specific index\"\"\"\n",
        "\n",
        "        def pad_data(data, length_visits, length_codes, pad_value=0):\n",
        "            \"\"\"Pad data to desired number of visits and codes inside each visit\"\"\"\n",
        "            zeros = np.full((len(data), length_visits, length_codes), pad_value)\n",
        "            for steps, mat in zip(data, zeros):\n",
        "                if steps != [[-1]]:\n",
        "                    for step, mhot in zip(steps, mat[-len(steps) :]):\n",
        "                        # Populate the data into the appropriate visit\n",
        "                        mhot[: len(step)] = step\n",
        "\n",
        "            return zeros\n",
        "\n",
        "        # Compute reusable batch slice\n",
        "        batch_slice = slice(idx * self.batch_size, (idx + 1) * self.batch_size)\n",
        "        x_codes = self.codes[batch_slice]\n",
        "        # Max number of visits and codes inside the visit for this batch\n",
        "        pad_length_visits = max(map(len, x_codes))\n",
        "        pad_length_codes = max(map(lambda x: max(map(len, x)), x_codes))\n",
        "        # Number of elements in a batch (useful in case of partial batches)\n",
        "        length_batch = len(x_codes)\n",
        "        # Pad data\n",
        "        x_codes = pad_data(x_codes, pad_length_visits, pad_length_codes, self.num_codes)\n",
        "        outputs = [x_codes]\n",
        "        # Add numeric data if necessary\n",
        "        if self.numeric_size:\n",
        "            x_numeric = self.numeric[batch_slice]\n",
        "            x_numeric = pad_data(x_numeric, pad_length_visits, self.numeric_size, -99.0)\n",
        "            outputs.append(x_numeric)\n",
        "        # Add time data if necessary\n",
        "        if self.use_time:\n",
        "            x_time = sequence.pad_sequences(\n",
        "                self.time[batch_slice],\n",
        "                dtype=np.float32,\n",
        "                maxlen=pad_length_visits,\n",
        "                value=+99,\n",
        "            ).reshape(length_batch, pad_length_visits, 1)\n",
        "            outputs.append(x_time)\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "9PcuXWJRRxUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(model_parameters, path_data, path_dictionary):\n",
        "    \"\"\"Read test data used for scoring\n",
        "\n",
        "    :param model_parameters: parameters of model\n",
        "    :type model_parameters: str\n",
        "    :param str path_data: path to test data\n",
        "    :param str path_dictionary: path to code idx dictionary\n",
        "    :return: tuple for data and classifier arrays\n",
        "    :rtype: tuple( list[class:`numpy.ndarray`] , :class:`numpy.ndarray`)\n",
        "    \"\"\"\n",
        "\n",
        "    data = pd.read_pickle(path_data)\n",
        "    data_output = [data[\"codes\"].values]\n",
        "\n",
        "    if model_parameters.numeric_size:\n",
        "        data_output.append(data[\"numerics\"].values)\n",
        "    if model_parameters.use_time:\n",
        "        data_output.append(data[\"to_event\"].values)\n",
        "\n",
        "    with open(path_dictionary, \"rb\") as f:\n",
        "        dictionary = pickle.load(f)\n",
        "\n",
        "    dictionary[model_parameters.num_codes] = \"PADDING\"\n",
        "    return data_output, dictionary"
      ],
      "metadata": {
        "id": "P2gBfQvyR4BW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_importances(alphas, betas, patient_data, model_parameters, dictionary):\n",
        "    \"\"\"Construct dataframes that interprets each visit of the given patient\"\"\"\n",
        "\n",
        "    importances = []\n",
        "    codes = patient_data[0][0]\n",
        "    index = 1\n",
        "    if model_parameters.numeric_size:\n",
        "        numerics = patient_data[index][0]\n",
        "        index += 1\n",
        "\n",
        "    if model_parameters.use_time:\n",
        "        time = patient_data[index][0].reshape((len(codes),))\n",
        "    else:\n",
        "        time = np.arange(len(codes))\n",
        "    for i in range(len(patient_data[0][0])):\n",
        "        visit_codes = codes[i]\n",
        "        visit_beta = betas[i]\n",
        "        visit_alpha = alphas[i][0]\n",
        "        relevant_indices = np.append(\n",
        "            visit_codes,\n",
        "            range(\n",
        "                model_parameters.num_codes + 1,\n",
        "                model_parameters.num_codes + 1 + model_parameters.numeric_size,\n",
        "            ),\n",
        "        ).astype(np.int32)\n",
        "        values = np.full(fill_value=\"Diagnosed\", shape=(len(visit_codes),))\n",
        "        if model_parameters.numeric_size:\n",
        "            visit_numerics = numerics[i]\n",
        "            values = np.append(values, visit_numerics)\n",
        "        values_mask = np.array(\n",
        "            [1.0 if value == \"Diagnosed\" else value for value in values],\n",
        "            dtype=np.float32,\n",
        "        )\n",
        "        beta_scaled = visit_beta * model_parameters.emb_weights[relevant_indices]\n",
        "        output_scaled = np.dot(beta_scaled, model_parameters.output_weights)\n",
        "        alpha_scaled = values_mask * visit_alpha * output_scaled\n",
        "        df_visit = pd.DataFrame(\n",
        "            {\n",
        "                \"status\": values,\n",
        "                \"feature\": [dictionary[index] for index in relevant_indices],\n",
        "                \"importance_feature\": alpha_scaled[:, 0],\n",
        "                \"importance_visit\": visit_alpha,\n",
        "                \"to_event\": time[i],\n",
        "            },\n",
        "            columns=[\n",
        "                \"status\",\n",
        "                \"feature\",\n",
        "                \"importance_feature\",\n",
        "                \"importance_visit\",\n",
        "                \"to_event\",\n",
        "            ],\n",
        "        )\n",
        "        df_visit = df_visit[df_visit[\"feature\"] != \"PADDING\"]\n",
        "        df_visit.sort_values([\"importance_feature\"], ascending=False, inplace=True)\n",
        "        importances.append(df_visit)\n",
        "\n",
        "    return importances"
      ],
      "metadata": {
        "id": "_wNFnzWXR8eP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, data, model_parameters):\n",
        "    \"\"\"Construct dataframes that interpret each visit of the given patient\"\"\"\n",
        "\n",
        "    test_generator = SequenceBuilder(data, model_parameters)\n",
        "    preds = model.predict_generator(\n",
        "        generator=test_generator,\n",
        "        max_queue_size=15,\n",
        "        use_multiprocessing=True,\n",
        "        verbose=1,\n",
        "        workers=3,\n",
        "    )\n",
        "    return preds"
      ],
      "metadata": {
        "id": "_uDAi-RmSD2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main Body of the code\"\"\"\n",
        "    print(\"Loading Model and Extracting Parameters\")\n",
        "    model, model_with_attention = import_model(PATH_MODEL)\n",
        "    model_parameters = get_model_parameters(model)\n",
        "    print(\"Reading Data\")\n",
        "    data, dictionary = read_data(model_parameters, PATH_DATA, PATH_DICTIONARY)\n",
        "    probabilities = get_predictions(model, data, model_parameters)\n",
        "    BATCH_SIZE = 1\n",
        "    data_generator = SequenceBuilder(data, model_parameters)\n",
        "    while 1:\n",
        "        patient_id = int(input(\"Input Patient Order Number. Type -1 to exit: \"))\n",
        "        if patient_id == -1:\n",
        "          break\n",
        "        if patient_id > len(data[0]) - 1:\n",
        "            print(\"Invalid ID, there are only {} patients\".format(len(data[0])))\n",
        "        elif patient_id < 0:\n",
        "            print(\"Only Positive IDs are accepted\")\n",
        "        else:\n",
        "            print(\"Patients probability: {}\".format(probabilities[patient_id, 0, 0]))\n",
        "            proceed = str(input(\"Output predictions? (y/n): \"))\n",
        "            if proceed == \"y\":\n",
        "                patient_data = data_generator.__getitem__(patient_id)\n",
        "                proba, alphas, betas = model_with_attention.predict_on_batch(\n",
        "                    patient_data\n",
        "                )\n",
        "                visits = get_importances(\n",
        "                    alphas[0], betas[0], patient_data, model_parameters, dictionary\n",
        "                )\n",
        "                for visit in visits:\n",
        "                    print(visit)"
      ],
      "metadata": {
        "id": "pSYFlZu-SIko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNta4PckT5mB",
        "outputId": "bafeb3f1-b4e9-47d1-9fd5-f48146cb5f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Model and Extracting Parameters\n",
            "Model bias: [-0.01536037]\n",
            "Reading Data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-fa95821a2417>:5: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  preds = model.predict_generator(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48/48 [==============================] - 4s 33ms/step\n",
            "Input Patient Order Number. Type -1 to exit: 1\n",
            "Patients probability: 0.5582164525985718\n",
            "Output predictions? (y/n): y\n",
            "      status feature  importance_feature  importance_visit  to_event\n",
            "0  Diagnosed   D_459           -0.000666          0.003685         0\n",
            "3  Diagnosed    D_19           -0.000685          0.003685         0\n",
            "2  Diagnosed   D_939           -0.001197          0.003685         0\n",
            "1  Diagnosed    D_05           -0.001514          0.003685         0\n",
            "       status feature  importance_feature  importance_visit  to_event\n",
            "7   Diagnosed    D_18            0.242035          0.996315         1\n",
            "8   Diagnosed   D_754            0.112312          0.996315         1\n",
            "6   Diagnosed   D_140            0.105042          0.996315         1\n",
            "3   Diagnosed   D_280           -0.014598          0.996315         1\n",
            "10  Diagnosed   D_075           -0.146047          0.996315         1\n",
            "9   Diagnosed    D_75           -0.159941          0.996315         1\n",
            "1   Diagnosed   D_483           -0.175265          0.996315         1\n",
            "5   Diagnosed   D_939           -0.324596          0.996315         1\n",
            "2   Diagnosed   D_901           -0.364470          0.996315         1\n",
            "0   Diagnosed   D_454           -0.379600          0.996315         1\n",
            "4   Diagnosed    D_05           -0.411098          0.996315         1\n",
            "Input Patient Order Number. Type -1 to exit: 3\n",
            "Patients probability: 0.3653091490268707\n",
            "Output predictions? (y/n): y\n",
            "      status feature  importance_feature  importance_visit  to_event\n",
            "4  Diagnosed   D_378            0.000665           0.00349         0\n",
            "3  Diagnosed   D_039            0.000531           0.00349         0\n",
            "0  Diagnosed    D_71            0.000433           0.00349         0\n",
            "2  Diagnosed   D_705            0.000305           0.00349         0\n",
            "1  Diagnosed   D_562            0.000265           0.00349         0\n",
            "      status feature  importance_feature  importance_visit  to_event\n",
            "1  Diagnosed     D_5            0.245802           0.99651         1\n",
            "6  Diagnosed   D_039            0.153108           0.99651         1\n",
            "4  Diagnosed    D_71            0.125321           0.99651         1\n",
            "2  Diagnosed    D_78            0.120481           0.99651         1\n",
            "5  Diagnosed   D_705            0.088360           0.99651         1\n",
            "3  Diagnosed    D_85           -0.031373           0.99651         1\n",
            "8  Diagnosed   D_050           -0.037373           0.99651         1\n",
            "0  Diagnosed    D_56           -0.132923           0.99651         1\n",
            "7  Diagnosed    D_72           -0.254347           0.99651         1\n",
            "Input Patient Order Number. Type -1 to exit: 9\n",
            "Patients probability: 0.2228209227323532\n",
            "Output predictions? (y/n): y\n",
            "       status feature  importance_feature  importance_visit  to_event\n",
            "0   Diagnosed   D_188            0.017938          0.039379         0\n",
            "4   Diagnosed   D_855            0.011310          0.039379         0\n",
            "5   Diagnosed    D_38            0.010767          0.039379         0\n",
            "7   Diagnosed    D_84            0.009995          0.039379         0\n",
            "6   Diagnosed   D_959            0.007271          0.039379         0\n",
            "9   Diagnosed   D_500            0.002731          0.039379         0\n",
            "2   Diagnosed    D_99            0.001552          0.039379         0\n",
            "13  Diagnosed    D_12            0.000193          0.039379         0\n",
            "11  Diagnosed   D_025           -0.001348          0.039379         0\n",
            "3   Diagnosed   D_824           -0.002668          0.039379         0\n",
            "1   Diagnosed   D_580           -0.004076          0.039379         0\n",
            "10  Diagnosed   D_586           -0.005470          0.039379         0\n",
            "12  Diagnosed    D_80           -0.006933          0.039379         0\n",
            "8   Diagnosed    D_72           -0.008072          0.039379         0\n",
            "       status feature  importance_feature  importance_visit  to_event\n",
            "1   Diagnosed    D_18            0.205469          0.960621         1\n",
            "2   Diagnosed    D_18            0.205469          0.960621         1\n",
            "7   Diagnosed   D_500            0.074908          0.960621         1\n",
            "10  Diagnosed   D_742            0.068806          0.960621         1\n",
            "3   Diagnosed    D_99            0.039293          0.960621         1\n",
            "4   Diagnosed    D_12            0.006630          0.960621         1\n",
            "8   Diagnosed   D_000           -0.068196          0.960621         1\n",
            "0   Diagnosed   D_580           -0.108234          0.960621         1\n",
            "11  Diagnosed   D_586           -0.147365          0.960621         1\n",
            "12  Diagnosed   D_586           -0.147365          0.960621         1\n",
            "6   Diagnosed    D_41           -0.185149          0.960621         1\n",
            "5   Diagnosed   D_191           -0.197340          0.960621         1\n",
            "9   Diagnosed    D_01           -0.295048          0.960621         1\n",
            "Input Patient Order Number. Type -1 to exit: -1\n"
          ]
        }
      ]
    }
  ]
}